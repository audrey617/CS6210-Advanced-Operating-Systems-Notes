# Lesson outline
- [L06a: Spring Operating System](https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/L06_Distributed%20Objects%20and%20Middleware.md#l06a-spring-operating-system)
- [L06b: Java RMI](https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/L06_Distributed%20Objects%20and%20Middleware.md#l06b-java-rmi)
- [L06c: Enterprise Java Beans](https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/L06_Distributed%20Objects%20and%20Middleware.md#l06c-enterprise-java-beans)

# L06a: Spring Operating System

<h2>1. Spring Operating System Introduction</h2>

<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/1.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Welcome back to the next module of the advanced operating systems course. Recall that the Cornell experiment that we saw as the last piece of the previous module argues for a component-based design to reduce the pain points in the development of complex software systems. Industries that are designing and commercializing production operating systems and distributed services through the client-server paradigm. There is another important pain point, and that is how to design for the continuous and incremental evolution of complex distributed software systems both in terms of functionality and performance. The short answer to the puzzle is distributed object technology.</li>
   <li>We saw how object technology is employed in the Tornado parallel operating system as a structuring tool to allow the scalability of operating system services in a parallel system. In this module of the advanced operating systems course, we are going to see examples of how distributed object technology is influencing commercial offerings in the computer industry.</li>
   <li>We'll start this lesson module with the discussion of the Spring system, which was designed and implemented in Sun Micro Systems as a network operating system for use in a local area network. Later on, Spring was marketed as Sun's Solaris operating system.</li>
   <li>Before we discuss the Spring system, a little bit of history and some personal connection. Yousef Khalidi, one of the chief architects of the spring system, got his PhD from Georgia Tech in 1989 developing the cloud's distributing operating system, which is an object based operating system. And he was my numero uno PhD student incidentally. Not surprisingly, the Spring system was heavily influenced by Yousef's work with clouds. And Spring came out commercially as Sun's Solaris MC product. And for the trivia buffs out there, Yousef is now heading Microsoft's Azure Cloud Computing product. By the way, Azure has nothing to do with the cloud system that Yousef developed as a grad student at Georgia Tech. Later on, when we discuss giant scale services and cloud computing, we will feature an interview with Yousef wherein he shares his thoughts on future evolution of distributed system services.
</li> 
</ul>

<h2>2. How to Innovate OS</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/2.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Now back to our discussion of the Spring system at Sun. There is always a quadrum of how to innovate in the operating system. Academia is ripe for pursuing ideas on the lunatic fringe, but if you are an industry, you are always worried about "should we do a brand new operating system or do a better implementation of a known operating system?" The marketplace usually constrains the research industry that it serves, specifically, if you're a company like Sun Microsystems, which made Unix workstations in its heydays between 1980 and 2005. And it was building large complex server systems which run 24/7 for a variety of applications, such as airline reservations and so on. And if you are in that marketplace, the question becomes, "should we build a brand new operating system or build a better implementation of a known operating system?" Marketplace demand says, "well, there are legacy applications running on your current operating system. Therefore, building a brand new operating system may not be that viable in an industrial setting."</li>
   <li>So the approach they took in the Spring system at Sun Microsystems is to be different but innovate where it makes sense. It is sort of like Intel inside. The idea is in processor architecture, Intel is dominant, and a lot of interesting computer architecture research happens in innovating under the covers in the microarchitecture. So the external interface is still a well-known interface like the Intel processor but underneath, they do a lot of innovation in the microarchitecture. In a similar manner, if you are a company like Sun Microsystems that peddles Unix boxes and want to retain your customer base, then you want to make sure that the external interface remains UNIX and the external interface remains as UNIX. But under the covers, you innovate where it makes sense. In particular, you want to make sure that everything that you do in the operating system allows third party vendors to develop software against the new APIs that you may provide in the operating system and integrate that into operating system, while at the same time making sure that such integration is not going to break anything. Or said differently, you want to preserve all the things that are good in standard operating systems, but at the same time, you want to make sure that the innovation allows extensibility, flexibility, and so on.</li>
   <li>That's sort of the approach that the Spring system took, and for all the things that I just said, using object orientation is a good choice to make sure that we can do innovation under the covers while keeping the external interface the same.
</li> 
</ul>

<h2>3. Object based vs Procedural Design</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/3.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>That brings us to a discussion of procedural design versus an object-based design.</li>
   <li>You're all familiar with procedural design where you're writing your code as one monolithic entity, and in a procedural world, you have shared state in terms of global variables, and you may have private state in the caller and the callee. And state is now distributed all over the place. So, basically, the interface between the caller and the callee is through the normal procedure call mechanism that one subsystem may make a procedure call that goes into another subsystem. And this is how monolithic kernels are built where state is now strewn all over the place. There maybe some shared state and private state of subsystems and so on, and this is typically how monolithic systems are built.</li> 
  <li>To contrast this procedural design to object-based design, in an object-based design, objects contain the state that is entirely contained within this object, not visible outside. There are methods inside this object that manipulate the state that is part of this object. So in other words, externally, the state is not visible, The only thing that is visible are the methods for invocation and these invocations work on the state that is local to the object. So what you get with an object-based design is strong interfaces and complete isolation of the state of an object from everything else, contrast that with the procedural design where the state can be strewn all over the place and the shared state can be manipulated from several different subsystems that are part of a big monolith. But in this case (Object-based), what we have is strong interfaces that completely separate one object from other objects, and the state that is specific to an object is contained entirely inside this object and invisible to other objects outside except via well-defined invocation methods that have been exposed by this object implementor to the outside world.</li>
   <li>As OS designers, the immediate question that might come up is, if we have these strong interfaces, it sounds similar to what we discussed when we talked about the structure of operating systems early on, and that is border corssing across protection domains. Is it going to cost us? But there are ways around it to make these border crossing performance conscious as well.</li>
   <li>Now, where to apply this object orientation? Well, in Spring, for instance, they applied object orientation in building the operating system kernel. So the key point to takeaway is, if object orientation is good at the level of implementing a high performance operating system kernel, it should be good at higher levels of the software as well. And while I am expounding the virtues of object-based design here, we have already seen this when we talked about Tornado system. That was also using an object-based approach to building operating system kernels.
</li>  

</ul>
<h2>4. Spring Approach</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/4.JPG?raw=true" alt="drawing" width="700"/>
</p>

<ul>
  <li>The Spring Approach to building operating system is to build strong interfaces for each subsystem. What that means is, the only thing that is exposed outside a sub-system is what services are provided by the subsystem but not how. In other words, the how part of it can be changed at any time, so long as the external interface remains unchanged. So that is what is meant by strong interfaces, and this naturally leads to object orientation.</li>
   <li>They also wanted to make sure that the system is open and flexible. And this is important if you're an operating system vendor and you want to integrate third party software into your operating system. You want to make sure that your interfaces are open and flexible and at the same time, you want to maintain the integrity of your subsystems, and that's why strong interfaces are extremely important.</li> 
  <li>Being open and flexible also suggests that you don't want everything to be written in one language. You don't want to be tied to a particular language for implementing all the system components, and this is the reason that in Spring they chose to use IDL, which is the interface definition language, and this is from the OMG group. There are IDL compilers that are available from several third party software vendors, and what that allows you to do is, you can define your interfaces using IDL. And third party software vendors can use that IDL definition of the interfaces and use them in building their own subsystems that can integrate with the Spring system. And the other part of a Spring approach is extensibility, and extensibility naturally leads to microkernel based approach and that's what you see here.</li> 
  <li>This is the structure of the Spring system and what you see below this red line is Spring's idea of a microkernel and in fact there are two parts to it. There is a nucleus, which in Spring is the entity that provides the abstractions of threads and interprocess communication among the threads. And the kernel itself is made up of nucleus plus the virtual memory manager. So if you have put these two things together, the nucleus gives you threads and IPC and the VM manager gives you memory management. And if you remember back to our good old friend Liedtke's principle of what a microkernel should provide. You see that what is below this red line is exactly Liedtke's principle that is the microkernel is providing the abstraction of threads in IPC and an abstraction of memory. And everything else is outside the kernel. All the things that are above the red line are outside the kernel, and, in particular, I mention that Spring is Sun Microsystem's answer to building a network operating system. Because this is a time when transitioning was happening to services that are being provided on the network. And so, they wanted to go from an operating system that runs on a single node to a network operating system using the same interface. Namely the Unix interface, and so this entity that you see here, which is called the network proxy. We'll see that, more of it, in later discussion in this lesson. This is the entity that allows machines to be connected to one another. All the ovals that you're seeing that are outside the kernel provide different services that you might need in your desktop environment. For instance an X11 server is a display manager and you may need ability to do shell level programming, and you need file system, and you need a way by which you can communicate in the network, meaning that you need a protocol stack.
</li> 
</ul>

<h2>5. Nucleus Microkernel of Spring</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/5.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Nucleus is microkernel of a Spring and it is subset of Liedtke's prescription as I mentioned just now. In the sense that, nucleus manages only threads and IPC. The abstractions available in nucleus are the following. There is this domain. A domain is similar to Unix process, it's a container or an address space, and threads can execute in a particular domain. These threads are similar in semantics to Pthread that we have seen before, and this abstraction called "Door" is a software capability to a domain. You can think of it as a real life analogy of opening a door in order to get into a room. In a similar manner, if you have a handle to the door you can open the door and enter a target domain. So that's the idea behind door. So, any domain can create these nucleus entities called doors, which are essentially entry points for entering the target domain. With the object orientation, I told you that the only thing that you can do is make invocations on objects, and the entry points available and the objects that are contained in a domain are represented by this abstraction called door provided by nucleus.</li> 
  <li>Let's say, I'm a file server. What will I do? Well I have entry points in my file server, such as, opening a file, or reading a file, writing a file, and so on. Basically, I will create those entry points as doors into my domain. If I'm a client, how do I get access to the entry point that's available in the target domain? Well, the way I do that is exactly similar to how you may be opening your file in a Unix file system. What you do is an fopen, and when you do that, you get a file descriptor, which is a small integer that is a handle for you to access that file. In a similar manner, if I'm a client and if I want the ability to invoke a target domain, a particular entry point, then what I want is an access to this door and the way I get that is by getting a door handle. So I get a door handle. So every domain will have this door table, which is similar to the file descriptors that you may have in a Unix process. And every door ID that you have in this door table points to a particular door. If I have a door handle in my door table for a particular door, what that tells me "oh, I have the ability to make an invocation in the target domain that this particular door corresponds to." So the possessor of a door handle is able to make object invocations on the target domain using this door handle. And as you can see, a particular client domain can have a door table that has access to several different target domains. So in this case, these two entries in my door table points to this door, which probably are entry points into this target domain. And other door which are a different set of entry points and I have access to them as well. And multiple clients may have access to the same door, because if it's a file system, for instance, you may be able to access the file system, I may be able to access the file system, and so on. So, the door table is something that is unique to every domain and it gives that domain an ability to access the entry points in the target domain, so that they can make object invocations.</li> 
  <li>The way to think about this door, it is basically a software capability to a domain. Since we are using object orientation, it is represented by a pointer to a C++ object that represents the target domain. And door can be passed from domain to domain but it is a software capability and it can be passed from domain to domain. When it is passed from domain to domain it gives the ability for those domains to actually get access to the entry points specified through the door to the target domain.</li>
   <li>The Spring kernel itself is a composition of the nucleus plus the memory management that is inherent in the fact that these domains represent an address space. Now, how do you go about making an object invocation, that is, you want to make a protected procedure call into a target domain from a client domain. How do I do that? Well, the nucleus is involved in every door call, so they won't open the door. I need the permission of the nucleus. And what I do is, when I make the invocation using the small descriptor that I have, which is a door handle, the nucleus looks at it, says "okay this domain has the ability to do this invocation". And it allocates a server thread on the target domain and executes the invocation that is indicated by this particular door handle. It's a protected procedure call, and since it is procedure call semantics, the client thread is deactivated, and the thread is allocated to the target domain, so that it can execute the invocation for the method that is indicated by this door handle. On return from this target domain, once that protected procedure call is complete, the thread is deactivated. The client thread is reactivated so that the client can continue with whatever it was doing before.</li>
   <li>So this is very similar to the communication mechanism that we discussed in the lightweight remote RPC paper before, in the sense that we're doing very fast cross address space calls using this door mechanism. This protected procedure call is in illustration of how nucleus makes sure that even though it has an object based design and it is using object orientation in the structuring of the operating system kernel. It ensures that it will still be performant, in the sense that you can do this cross domain calls very quickly through this idea of deactivating the client thread and quickly activating the thread to execute the entry point procedure in the target domain and on return reactivating the client thread. All of this results in very fast cross address space calls through this door mechanism. That's how you make sure that you get all the good attributes of object orientation and not sacrifice on performance at the same time.
</li> 
</ul>

<h2>6. Object Invocation Across the Network</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/6.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Spring is a network operating system. So, what I just described to you was how object invocation works within a single node. These doors are confined to the nucleus on a single node. We need to be able to do object invocation across the network. The client domain may be over here and the server domain may be on a different node on the local area network. Object invocation between client and server across the network is extended using network proxies.</li> 
  <li>For example, on the client box there is this Proxy B and on the server box there is the Proxy A. Proxies can be potentially different for connecting to different servers. So, this client may talk to this server using this proxy B. And may talk to a different server which I'm not showing here using a completely different proxy (for example, Proxy C). In other words, the proxies can potentially employ different protocols. That's where you have the opportunity to specialize. Whether the communication that's happening between the client and server is on the local area network or on a wide area network and so on, depending on that you can employ the protocol that is appropriate for use in the proxy. So, this is a key property of building a network operating system in Sun where they wanted to make sure that decisions are not being ingrained in the operating system of a single node in terms of the connectivity of that node to other nodes on the network. Depending on where the servers for a particular client is going to be maintained, that is where the location of the server is, you can employ different protocols to talk between the proxies that are on the client machine and the server machine. And also the proxies are invisible to the client and the server. In other words, the client and the servers are unaware whether they are both on the same machine or on a different machine. And they don't care.</li> 
  <li>Let's see how this client-server relationship is established using these proxies. So when a client-server connection has to be made across the network. The first thing that happens is that you instantiate a proxy on the server node, and establish a door for communication between the Proxy A and the server domain through the nucleus on the server machine. And now Proxy A is going to export a network handle embedding this Door X to its peer proxy B that is on the client domain. This interaction between Proxy A and Proxy B is outside of the purview of the nucleus. So the network handle that is being established has nothing to do with the primitives or the mechanism that are available in the nucleus of the Spring system. So what proxy A is doing, is to create a network handle embedding this Door X. And it is going to export that to this proxy B. And proxy B has a door that it has established locally on nucleus B so that the client domain can communicate with it. And now what proxy B will do, is it will use the network handle that has been exported by Proxy A to establish a connection between the two nucleus. So this network handle and the communication that goes on between these two guys is not through the nucleus. That's important for you to understand.</li>
   <li>So now, how does the client make an invocation on the server domain? Well, when the client wants to make an invocation, it thinks that when it is accessing Door Y, it is accessing the server's domain. But it isn't. What it is accessing, is this Proxy B and of course access to this Door Y, which is in Proxy B, is blessed by Nucleus B, and when this invocation happens, Proxy B then is going to communicate through this network handle that it has with its peer Proxy A. And the peer Proxy A, when it gets this client invocation proxied through this Proxy B and arriving at Proxy A, will know that "oh, this is really intended for the server domain. And I know how to access that through the door that I have in the server domain, and it uses the door it has in the server domain in order to make the actual invocation." So to recap, what is really going on, the client wants to open this Door X. It doesn't have a direct handle on Door X because server domain is in a different node of the network. And therefore, the way remote invocation is accomplished, is by the server domain's door which is the entry point into the server domain, is passed on by this proxy via a network handle to its peer proxy on a different node, in this case the client node. And once this network handle is available to proxy B, it can establish the connection between these nucleus, and once this connection is established, then the client domain, it thinks it is making an invocation call for Door X, but in fact it is being passed through Door Y to this proxy. And the proxy B uses a network handle to communicate that invocation over to proxy A which then uses the actual door that will open the invocation call under server domain and execute the client domain's call.</li> 
</ul>

<h2>7. Secure Object Invocation</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/7.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>It may often be necessary for a server object to provide different privilege levels to different clients. For instance if you have a file server the file server may have different access privileges to different classes of users. In order to facilitate that kind of a differential invocation of objects, the security model that Spring provides is via what is called a front object. So this is the underlying object. An underlying object may have a front object that is completely outside of the Spring semantics for object invocation. The connection between the front object and the underlying object is entirely within the purview of the implementer of the service. In other words, this connection is not through the door mechanism that Spring system provides you. So, all that the client domain is going to be able to do is access the front object. And the front object will register the door for accessing it with the nucleus, so that the client can go through this door to this front object, and the front object is the one that is going to then check the Access Control List, ACL, in order to see what kind of privileges this client domain has in order to make an invocation on the underlying object. And it is possible to have multiple front objects to the underlying objects with distinct doors registered with the nucleus for different implementation of control policies that you want for a particular service. So, in other words, the policies that you want for accessing the services available in an underlying object can be implemented in this front object or different instances of this front object depending on how many different control policies you want. So when a client invocation comes in through this door to the front object, the ACL, the access control list is checked before allowing this invocation to actually go through to the underlying object.</li> 
  <li>As I mentioned earlier if this client domain has access to an invocation entry point in a server, that is it has access to a door, the client domain can pass this around because of the software capability. And the software capability can be passed around by the client domain to other domains in order to use that same capability to access the same object. But in so doing the client domain can decide whether it wants to give the same privilege for accessing this object or lesser privilege than what it has. Those are the things that can be implemented as policies through this front object.</li> 
  <li>For example, let's say that the user wants to print a file foo. The user, of course, has full access to the file system for this particular object, that is the file that the user has created. This is a reference to the object foo and user has full access to that. It wants to print the file. But it doesn't want to give privilege to the printer object any more privilege than it needs to have to print this. In particular, if I want to print a file, all I need to do is give a one-time privilege to the printer object. So I'm going to take this capability that I've got for this file foo, reduce the privilege level and say that you've got a reference to the same object, but you have a one time reference. Now the printer object can access the file system and present its capability, and the front object, which is associated with the file system, will verify that "yes, the one-time ticket that this guy has is not expended yet," and therefore it is allowed to access this file so that it can do its job of printing. But if it tries to present the same handle again, it'll be rejected by the front object associated with the file system because this is a one-time reference. The capability that is being provided by the user the printer is a one-time capability.</li> 
  <li>So we've seen how object invocation can happen efficiently through the door mechanism and the thread hand-off mechanism that I mentioned within a single node, and it can happen efficiently across the network through the proxies, and it can also happen securely by the fact that you can associate policies in front objects that govern access to the objects. So these are all the mechanisms that are provided in the Spring kernel and this is where the innovation happens. Or in another words, the external interface, even though it is a Unix operating system, under the cover, the Spring system does all of these innovation in terms of how to structure the operating system itself using object technology.
</li> 
</ul>

<h2>8. Abstractions</h2>

<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/8.JPG?raw=true" alt="drawing" width="500"/>
</p>

<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/9.JPG?raw=true" alt="drawing" width="500"/>
</p>


<h2>9. Virtual Memory Management in Spring</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/10.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>So virtual memory management is part of the kernel of Spring, and now we will talk about how virtual memory management happens in the Spring operating system. There is a per machine virtual memory manager, and the virtual memory manager is in charge of managing the linear address space of every process. As we know, the linear address space of a process is what the architecture gives you, and what the virtual memory manager does is to break this linear address space into regions. And you can think of regions as a set of pages. So you take the linear address space given by the architecture, that's the process address space, break that up into regions, but each region is a set of pages. And each region can be of different sizes.</li> 
  <li>The second obstraction in the virtual memory management system is what is called a memory object, and the idea of breaking up this linear address space into regions. Is to allow these regions to be mapped to different memory objects. So, for instance, this region is mapped to this memory object. This region is mapped to a portion of this memory object. And these two regions, different regions of the same address space are mapped to the same memory object and this is perfectly fine. So, this is how the Virtual Memory Manager takes the linear address space and maps it to these memory objects. And what are these memory objects? The abstraction of a memory oject allows a region of virtual memory to be associated with a backing file. Or it could be the swap space on the disk, and things like this. So this memory object is the mechanism by which portions of the address space can be mapped to different Entities, which maybe on the disk as swap space or files in a file system. All of those are available to the abstraction of the memory object, so that regions in an address piece can be mapped to the backing entities. And it is also perfectly possible that multiple memory objects may map to the same backing file that is also perfectly possible. so the way to think about these abstractions is linear address space broken into regions, regions mapped to memory objects, and memory object is an abstraction for things living on backing store, meaning a disk. It could be the swap space on the disk, or it could be specific files that are being memory mapped in order to access from a process address space. Those are the abstractions available in the virtual memory management system, now we'll see how these memory objects Are then paged in and brought into the physical memory.
</li> 
</ul>

<h2>10. Memory Object Specific Paging</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/11.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>So here is a virtual memory manager and it is responsible for an address space that it is governing and this is the guy that is going to worry about breaking a linear address space into regions and mapping those regions to specific memory objects. For a particular process that is living in an address space to access a particular memory object. Obviously, this memory object has to be brought into DRAM and that is what a pager object is going to do, which is equivalent to the idea of what is called external pages in other systems, such as Mach.</li> 
  <li> A pager object is responsible for making or establishing the connection between virtual memory and physical memory. And a portion of the virtual memory that is a region of the linear address space has been mapped to this memory object, and it is the responsibility of this pager object to make sure that this memory object has the representation in the physical memory when the process wants to access that portion of the address space range that corresponds to this memory object. So this pager object creates what is called a cached object representation for the memory object in the DRAM. So now, the portion of the address piece, that is the region of the address piece that this virtual memory manager mapped to this memory object one becomes available for the process to address in its DRAM because of the work done by this pager object in mapping this memory object into this DRAM.</li> 
  <li>Similarly, a different virtual memory manager object. Managing a different address space can similarly map another memory object and clear a cache representation for this address space to map a region of its address space to this memory object using this pager object. I mentioned that the address space manager can make any number of such mapping between regions of the linear address space and memory objects.</li> 
  <li>For instance, there's another region of the linear address space that is mapped to this memory object too, and there may be a pager object that governs the paging of this object into a DRAM representation. So there's a cached object representation for this memory object which is part of the region Of the linear address space of a particular process managed by this VMM1. So in this example, this pager one is a pager for two distinct memory objects, memory object one and memory object two, and which are cached by VMM1 on behalf of a process. So there are two pager objects. One for each one of these things.</li> 
  <li>The important point I want to get across is that there's not a single paging mechanism that needs to be used for all the memory objects. So it gives you an ability to have different regions of the linear address space of a given process by associating different pager objects with each of the regions that correspond to a particular memory object. And all of these associations between regions and memory objects can be dynamically created. So for instance, this address space manager may decide to associate a region in this linear address space to this memory object. If it does that, then there is a new pager object that. Is going to manage their association between the region of the virtual address space that is mapped to this memory object three and the cached object representation is the DRAM representation of this memory object created by a pager object that is managing the relationship between this region. And this particular memory object three.</li> 
  <li>This is an interesting situation, because you have a memory object that is shared by two different address spaces. And there are two distinct pager objects associated with managing The region of the address space in VMM 1 that maps to this memory object, and the region of the address space in VMM 2 that maps to the same memory object. Now what about the coherence of the cache representation of this object that exists over here? And the cached representation of this object that exists over here. Who manages that? Well it's entirely up to the pager object ever instantiated. In order to manage the mapping between this memory object and the cached object. So if coherence is needed. For the cache representation of this memory object in the DRAM of this address space and this address space, then it is a responsibility of these two pager objects to coordinate that. So it's not something that string system is responsible for, but it provides the basic mechanisms through which these entities can manage the regions that they are mapping. In terms of the memory objects and the DRAM representation of those objects. So in other words, external pagers establish the mapping between virtual memory, which is indicated by these memory objects, and physical memory, which is represented by the cached objects.</li> 
  <li>So in summary, the way memory management works in the spring system is, the address space managers are responsible for managing the linear address space of a process, and they do the mapping of the linear address space of a process by carving them up into regions. And associating the regions with different memory objects, and these memory objects maybe swap space on the disk. Or it could be files that are being mapped into specific regions of the linear address space. Entirely up to the application, what they want to do with it, but these abstractions are powerful for facilitating whatever may be the intent of the user. And mapping the memory objects to the cache representation, which lives in DRAM, is the responsibility of pager objects. And you can have any number of external pages that manage this mapping. And in particular, through this example I've shown you that you can have, for a single linear address space, multiple pager objects that are managing different regions of that same address space. And that's the flexibility and power that's available in the structure of the spring system using the object technology.
</li> 
</ul>

<h2>11. Spring System Summary</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/12.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>So to summarize the facilities of the perimeters available in the spring system. Object orientation, object technology permeates the entire operating system design. Its used as a system structuring mechanism in constructing a network operating system. To break it down, in the spring system you have the nucleus which provides you threads and IPC among threads.</li> 
  <li>The microkernel prescription of Liedtke is accomplished by the combination of nucleus, plus the address space management that is part of the Spring System's kernel boundary. And everything else lives above this kernel, meaning all the services you normally associate with an operating system such as file system, network communication and so on, were all provided as objects that live outside of this kernel.</li> 
  <li>The way you access those objects is through doors. And in every domain there is a door table that has a set of capabilities that a partiuclar domain has for accessing doors on different domains. And this door and door table is the the basis for cross domain calls.</li> 
  <li>Through the object orientation, and through the network proxies you can have object invocation implemented as protected procedure calls both on the same node and across machines.</li> 
  <li>Finally, it does virtual memory management by providing certain basic parameters, such as the linear address space, the memory object, external pages, and cached object representation.</li> 
  <li>Now to contrast this to Tornado. In Tornado also we saw that it was using object technology, but the contrast is pretty distinct. In Tornado it uses clustered object as an optimization for implementing services. For example, weather a particular object is singleton representation, or it has multiple representation for each processor, etc. Those are the kinds of optimizations that are being accomplished using the clustered object in the Tornado system. Whereas in the Spring system, object technology permeates the entire operating system design in that it is used as a system structuring mechanism, not as just an optimization mechanism in constructing a network operating system.
</li> 
</ul>

<h2>12. Dynamic Client Server Relationship</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/13.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Spring is a network operating system and the clients and the servers can be on the same machine, can be on different nodes on a local area network and in the Spring system, what they wanted to do was this idea of extensibility. They wanted to carry it to saying the client and the server should be impervious to where they are in the entire network. So the interaction should be freed. Or in other words, the client server interaction should be freed from the physical location of the clients and the servers. So for instance, in this picture, the clients and the servers are on the same machine. We've decided to replicate the servers in order to increase the availability, and now we have several copies of the servers and the clients are dynamically loaded to different servers for load distribution. And for those of you who are familiar with, you know, how services like Google work today, this is exactly what happens in services that we use on an everyday basis when we access Google. Our client requests are being routed to different servers and this is the same sort of thing that is happening in the Spring system that once you replicate the server, you want the client request to be routed to different servers depending on the physical proximity of the client to the servers, as well as the load that is currently being handled by one server versus another. Another variation of the same theme is where the server is not replicated, but the server is cached, for instance if it is a web server. Then there could be a proxy for the web, web server that is cached, and in that case the client request need not go to the origin web server, but it can go to the cached copies that are available. And so here again this decision of routing a client request to a particular cached copy of the server is dynamically taken. Not all of this sounds like magic in terms of how this client server relationship is being dynamically orchestrated, whether are in the same machine, or whether we dynamically decide to replicate the servers and decide to route the request to different servers, or we want to cache the servers and route the client request to different cache copies. All of these are dynamic decision that are taken. And how is this done? Well that's the part that we're going to see next.
</li> 
</ul>

<h2>13. Subcontract</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/14.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>The secret sauce that makes this dynamic relation between the client and the server possible is this mechanism called subcontract. It's sort of like the real life analogy of off loading work to a third party, you know, you give subcontract to somebody to get some work done. That's the same analogy that is being used here, in the structure of the Spring network operating system. I mentioned earlier, that the contract between the client and the server is established thru the IDL. That is the Interface Description language, used to create the contract between the client and the server. And the subcontract is the interface that is provided for realizing the IDL contract between the client and the server. So here is the IDL interface and the client is using the server's IDL interface to make invocation calls on the server. An implementation of this IDL interface is accomplished through the Subcontract mechanism. Put differently, subcontract is a mechanism to hide the runtime behavior of an object from the actual interface. For instance, there could be a singleton implementation of the server, or it could be a replicated implementation of the server. The client does not care, and does not know. And all of the detail of how this client's IDL interface is satisfied is in the details of the sub contract itself. So what that means is, the client side stub generation becomes very simple because all of the detail of where the server is. How to access the server? Whether the server is on the same machine or on a different machine and are there multiple copies of the server? Which copy of the server should I go to? All of those details are in the subcontract mechanism. That makes the life of client side stub generation very simple.</li> 
  <li>Subcontract lives under the covers of the IDL contract and you can change the subcontract at any time. So, for instance, if you don't like the work being done by one contractor, you give it to a different subcontract. Same sort of thing that can happen here is that the subcontract is something that you can discover and install at runtime. So, in other words, you can dynamically load new subcontracts. For instance, if a singleton server got replicated, then you get a new sub-contract that corresponds to this replicated server, so that now you can access the replicated servers using the subcontract. And nothing needs to change above this line. The client stub doesn't have to do anything differently. All of the details are handled by this subcontract seamlessly. So in other words, you can seamlessly add functionality to existing services using the sub contract mechanism.
</li> 
</ul>

<h2>14. Subcontract Interface for Stubs</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/15.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Now let's look at the interface that's available for the stub that is on the client side and the server side through the subcontract mechanism. The first interface, of course, is for marshaling and unmarshaling. So the client side stub has to marshal the arguments form the client and in order to do that, it has calls that it can make on the subcontract saying that marshal these arguments for me. The subcontract will do that for you. Depending on whether this invocation is going to go to a server that is on the network or is it on the same machine. Or, is it on different processor on the same machine? All of those details are buried in the subcontract. And therefore, when the client stub wants to marshal the arguments for a particular invocation, it just calls the subcontract and says please marshal these arguments for me, and the subcontract knows the way in which this particular invocation is going to be handled, and so it can then do the appropriate thing for marshaling the arguments based on where the location of the server is. That's the beauty of the subcontract mechanism, and this is true on the server side as well as on the client side. And once the marshaling has been done, the client side can make the invocation. And when it makes the invocation, once again the subcontract says I know exactly where this particular invocation is going to go to. So it takes care of that. So the subcontract on the client side has this invocation mechanism obviously because the client is the guy that is going to make the invocation. On the service side the subcontract gives a different set of mechanisms. It allows the server to revoke a service, or it allows a server to tell the subcontract that yes, I'm open for business by saying I'm ready to process invocation requests. So what you see is that the client side and the server side, the boundary is right here. The client stub and the server stub don't have to do anything differently, whether the client and the server are in the same machine or in a different machine. Replicas of the machine, cache copies of the machine, none of those things make a difference in terms of what the client, when I say client I mean the client application plus the client stub, and similarly, the server plus the server stub, they don't have to do anything different. All of the magic happens down below in the subcontract mechanism. So to recap, the innovations in the spring system. It uses object technology as a structuring mechanism in building a network operating system and it ensures through the object technology that it is providing strong interfaces, it is open, it is flexible, and it is also extensible because it is not a monolithic kernel. It has a microkernel, and all the services are provided through these object mechanism living on top of the kernel. And the other nice property is that the clients and the servers don't have to know whether they are colocated on the same node or they exist on different nodes of the local area network. And object invocations across the network are handled through the network proxies. And the subcontract mechanism allows the client and the servers to dynamically change the relationship in terms of who they are talking to. You can get new instances of servers instantiated and advertise that through the subcontract mechanism so that the clients can dynamically bind to new instances of servers that have been created without changing anything in the client side application or the client side stub. So those are all the powers that exist when you decide how to innovate under the covers, which is exactly what Sun did with the spring system.
</li> 
</ul>

<h2>15. Spring Operating System Conclusion</h2>
<ul>
  <li>The journey in this lesson should have given you a good idea of how it is possible to innovate under the covers. Externally, Sun was still peddling UNIX boxes, but internally they had completely revolutionized the structure of the network operating system through the use of object technology. If fact, the subcontract mechanism that Sun invented as part of the Spring system forms the basis for something that many of you who are Java programmers are using a lot, namely Java RMI. In this lesson that you're going to look at, we are going to study Java RMI and also Enterprise JavaBeans.</li> </ul>

# L06b: Java RMI
<h2>1. Java RMI Introduction</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/16.JPG?raw=true" alt="drawing" width="500"/>
</p>
<ul>
  <li>In this lesson, we will continue to see examples of how, distributed object technology is influencing commercial offerings in the computer industry. First, we'll discuss java RMI, which has it's roots in the basic principles of distributed systems that we have been seeing so far. Before we start talking about Java RMI ,let's have a fun quiz to prime the pump.
</li> 
</ul>

<h2>2. Java Language</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/17.JPG?raw=true" alt="drawing" width="500"/>
</p>

<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/18.JPG?raw=true" alt="drawing" width="500"/>
</p>

<h2>3. Java History</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/19.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Java was invented by a gentleman by the name of James Gosling at Sun. It was originally called Oak, and it was intended for use with PDAs. Then when in the 90s, there was a lot of interest in video on demand using the internet, Sun thought that Java maybe the right language for programming set-top boxes, but unfortunately the cable TV industry went with SGIF for the VOD trials, and so Oak fell flat at that point. And Sun all but gave up on Oak then the World Wide Web caught on and Java got a new life with the need for containment of what happens on the client boxes connecting to the World Wide Web. And today a lot of internet e-commerce depend a lot on the Java framework. The intent in this lesson is not to talk about the Java language itself but the distributed object model of Java.
</li> 
</ul>

<h2>4. Java Distributed Object Model</h2>

<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/20.JPG?raw=true" alt="drawing" width="500"/>
</p>
<ul>
  <li>The nice thing about the Java remote object model is that much of the heavy lifting that an application programmer has to do in building a client-server system using RPC. Things like marshaling, unmarshaling, publishing the remote object on the network for the clients to access. They're all subsumed under the covers by the Java distributed object runtime. And this is where one can see the similarity between the subcontract mechanism in the spring system that we saw recently, which was the origin in some sense for the Java RMI.>Before we dig deeper, let me give you at a high level the distributed object model of Java.</li> 
  <li>The term remote object in the object model of Java, refers to objects that are accessible from different address spaces. And the term remote interface is used in the distributed object model to say what are all the declarations. For methods in a remote object. </li> 
  <li>Once you have a remote object the interface, remote interface is saying what are all the declarations for methods that are existing in the remote object that are accessible from clients anywhere. That's what remote interface is.</li> 
  <li>And then the distributed object model of Java, the clients have to deal with RMI exceptions. So that's the failure semantics of the distributive model that the clients have to deal with exceptions that might happen when a remote method is invoked by a client.</li> 
  <li>And there are some similarities and differences between local objects in Java and remote objects. The similarity is that you can pass object references as parameters when you make a an object invocation. An object invocation arguments of the invocation could include object references. That's the similarity, but the difference is that the parameters. When it is passed, it is passed as value result. That's the difference between local object and, and remote object. In the case of local object, when you pass an object reference as a parameter, then the method that is invoked can reach into that object that has been passed as a parameter as a reference and make modifications to it and that modifications will get reflected. In the original object but in the distributed model, because the object references are passed as value result. If going across a network, that is passed as value result meaning the copy of their object is actually sent over to the invoked method and that invoked method is seeing the copy of the object and it is even though there is a reference being given. But the reference is actually converted into value result in the parameter passing mechanism for the distributed object model. So that's a fundamental difference in parameter passing. So they're both similarities in the sense that you can pass object references as a parameter. But the difference is the reference is passed in a value result mode, as opposed to a pure reference. So, in other words, once an object reference has been passed as a parameter to the server. If the client makes changes to that particular object whose reference is being given in the invoked method, those changes, the server will not see it, because that is local to the client. That's fundamentally different from between the local object model of Java and the distributed object model of Java.
</li> 
</ul>

<h2>5. Bank Account Example</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/21.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Let's put this distributed object model of Java to work. And, the example that I'm going to construct is a bank account server. And, the server has obvious API's for accessing your bank account, you can deposit, you can withdraw, and you can ask for a balance. So, those are the API's that the server is going to provide as a service. Now, the question is. How best to implement it using Java. In particular, given that ,there is the remote object and the remote interface available as mechanisms in the distributed object model, what would be the best way to construct this service as a distributional object, accessible from clients anywhere in the network? Let's consider two possibilities.
</li> 
</ul>
 
<h2>6. Reuse of Local Implementation</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/22.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>So the first possibility, or the first choice is reusing a local implementation. So let's say that the developer has access to a local implementation of a class called account. And she then takes that class account and derives and extends it to create public methods in the API bank account, and creates a bank account implementation. So she started with a local implementation of a class account and extended it to implement the bank account. Now this bank account service that has been created, she has to make that visible outside, in the network, so that any client can access it. So this is where she uses the built-in class available in the distributed object model of Java called the remote Interface. And what she does is, using that built in remote class that's available in the distributed object model of Java, she makes the methods in the bank account class that she created visible on the network. As a result of this, so now she's created this interface derived from the remote interface she has created, this interface for her bank account object. And so this interface becomes now publicly available for anyone to access. So clients on the network can have access to this interface bank account. Now she instantiates this bank account implementation. . What happens when the bank account implementation is actually instantiated? The location of the bank account implementation object, the instantiation that she has done, is not visible to the client. All that is visible to the client is the interface. The actual location of the object is not something that is visible to the client, and therefore the implementer has to do the heavy lifting of finding a way to make the location of the service visible to the clients on the network. So in the first choice, all that we used was the built-in class and the distributed object model of Java, which is a remote interface to publish the interface for a facility that we created. In this case, the bank account and the methods in it. And once we publish it, that interface is available. Because we derived it from the remote interface, the int, the specific interface, bank account interface, is available for any client on the network. However, when we instantiate the object, the location of the object where that service is available is not something that is readily visible to the client. And so the heavy lifting has to be done by the implementer to make that object that had been instantiated visible on the network.
</li> 
</ul>

<h2>7. Reuse of Remote</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/23.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Now a second choice is reusing the remote object class that's available in the Java distributed object model. As before, the developer writes the bank account object providing the methods for deposit, withdrawal and balance and publishes the methods that are in the object using the remote interface. So that, this bank account interface now becomes available for any client that wants to access that object. The reason this interface becomes available to the client is because you're extending this remote interface class that's available in the distributed object model of Java. However, note how the bank account implementation is actually derived. It is derived from the Java built in classes for remote object, and remote server. So, you extend the remote object and the remote server in order to get this bank account implementation object. Now, when you derived your bank account implementation object from the built in distributed object model of Java, namely the remote object and the remote server classes. Now when you instantiate your bank account implementation object, it becomes instantly visible to the network clients. You don't have to do any of the heavy lifting. So once the public methods for the bank account implementation are written by inheriting these built-in classes of Java, all the way starting from the remote interface, the remote object and the remote server. When the bank account implementation object is instantiated the server becomes instantly visible, magically visible to remote clients through the Java runtime system. That's the power of the distributed object model of Java. So the second choice of reusing remote object class in order to derive this implementation results in the heavy lifting being done by the Java magic. So, all of the heavy lifting needed to make this bank account implementation object visible to network clients is being done by the Java runtime. Now that I've given you the difference between the two choices, one using remote interface, and the other deriving your object from the remote object from the remote server. Time for a quiz.
</li> 
</ul>

<h2>8. Implementation Preference</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/24.JPG?raw=true" alt="drawing" width="500"/>
</p>

<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/25.JPG?raw=true" alt="drawing" width="500"/>
</p>

<h2>9. Java RMI at Work (Server)</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/26.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>So let's see Java RMI at work. On the server side, it's a three-step process to make the server object visible on the network. You instantiate the object. Once you instantiate the object, you create a URL, whatever you want to call the URL. And then you go to the Java runtime, and the facility that's available in the Java runtime For binding the URL that you created with the instance of the object that you created. The object that you instantiated; it binds it to this URL and it is now in the naming service of the Java runtime system. For clients to be able to discover the existence of this new service that you created and made it available on the network.
</li> 
</ul>

<h2>10. Java RMI at Work (Client)</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/27.JPG?raw=true" alt="drawing" width="500"/>
</p>
<ul>
  <li>Now let's look at the client side. Look at the ease with which any arbitrary client on the network can access the server object. What a client will do is, look up the service provider, by contacting a boot strap name server in the Java RMI system. And, it does a look up of the URL and when it does this look up, so this URL is published, once it is published, then it can look up this URL. And when it does this look up of this URL using the facility that's available in the Java RMI system, then a local access point for that object is created on the client side. And so now we've got the access to the object that is at the server through this local name account. And once I have that, then I can do invocations on the methods that is available in this server object by simply calling those methods. I can do a deposit. I can do a withdrawal. I can do a balance check. All of this, they look like normal procedure calls so far as the client is concerned. But each of this is really a call that is going out to the server wherever that server happens to be, and the Java Runtime system knows how to locate that server in order to do this invocation. That's the power of the Java RMI. The client does not know and does not care the location of the server. And if there a failures in any of these function executions, then remote exceptions will be thrown by the server through the Java run-time system back to the client. Of course with the networked nature of this client/server relationship, if a remote expression is thrown and the client sees that the invocation did not succeed, which is a reason the client saw an exception thrown. It may have no way of knowing at what point in the invocation the call actually failed. And this is one of the problems when you have services that you have to reach across the network and you have to handle the exception.
</li> 
</ul>

<h2>11. RMI Implementation (RRL)</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/28.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Now that we understand the distributed object model of Java and how to build services using the distributed Java object model and publish it and make it accessible to the clients. let's look at how the RMI is actually implemented? At the core of the RMI implementation is this layer called Remote Reference Layer, RRL. And that's the place where a lot of magic happens. The client site stub, is going to initiate a remote method invocation call using this Remote Reference Layer, and all of the magic with respect to marshaling the arguments. In order to send it over the network and so on is handled entirely by this Remote Reference Layer. And similarly when the result comes back unmarshaling the results into the data structures, that the client understands is once again accomplished using this RRL layer. On the server side. The skeleton that exists is therefore unmarshaling the arguments that comes from the client. And in order to unmarshal the argument, the skeleton uses a Remote Reference Layer, because a Remote Reference Layer knows how to unmarshal the arguments that are coming in. And the the skeleton then makes the call up to the server that is implementing the remote object. Once the server is done with the service, the skeleton marshals the result, and once again goes through the Remote Reference Layer to send it over to the client. And when it comes back, the Remote Reference Layer and the stub work together to deliver the results in a digestible format to the client.</li> 
  <li> marshaling and unmarshaling, they're also called serializing and deserialization in the Java world. Marshaling and unmarshaling are also called serializing and deserializing Java objects, and all of that is being done by the RRL layer. So basically, the objects that are being passed this arguments, they are serialized by the RRL, and deserialized. On the server end, and given to the server. And similarly, the result, which is also an object, is serialized using the Remote Reference Layer. And when it arrives on the client side, it is deserialized, and delivered as a result object back up to the client. Now where are the clients and the servers? Are they on the same machine, on a different machine? Of course we're talking about networked services, and, so the server's going to be remote. But the server could have several instances. There could be a single instance of a server, or there could be multiple instances of the server and the server may have ability for doing persistence and so on. Where is all that magic happening? Well, similar to the subcontract layer that we discussed in the spring system, the Remote Reference Layer is doing all the magic with respect to. Where the server is? How the server is handling request? Is it replicated? Is it a singleton server? All of these things are being handled through the Remote Reference Layer. So what that means is it allows for various invocation protocols between the client and the servers. And all of those things are buried in the Remote Reference Layer. And the actual clients and the servers can be impervious to those details. So, the Java run time stack, the RRL layer is a very crucial layer. And it has functionalities very similar to the subcontract mechanism and the spring system. And as I mentioned earlier Java RMI derives a lot from the subcontract mechanism. And, so there is not much surprise that there are similarities between the RRL layer and the subcontract mechanism. Having discussed RRL, let's go and talk about, the transport layer.
</li> 
</ul>

<h2>12. RMI Implementation Transport</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/29.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>The abstractions that the transport layer provides are endpoint, transport, channel, and connection. And I'll talk about each of these things in a little bit more detail. Endpoint you can think of as nothing but a protection domain or you can say it is a Java virtual machine. And it has a table of remote objects that it can access. And so this gives you a protection domain or a sandbox for execution of a server cord or a client cord can exist within the sandbox. That's what end point. Its basically a protection domain. Connection management, is the interesting piece that is what is about all the details of connecting these end points together. And in particular, the connection management of the transport layer of the Java Runtime system is responsible for setting up connections, tearing down connections, listening for incoming connections, and establishing the connection. And when a connection is established. Between two end points there's a distraction that I mentioned called transport comes into play. So, for instant between this end point, and this end point, thec connection manager decided to have udp transport. So a channel is established between this end point and this end point to do udp transport between these two end points. And so this is the functionality of the UDP transport that is incorporated in this transport layer. And similarly, between this endpoint and this endpoint, the connection manager decided to use a TCP channel, so the transport that is being used here is a TCP connection, both ends. We have a TCB connection at both ends to connecting this endpoint with this endpoint. Notice that a given endpoint, can have different transport for talking to different endpoints depending on a variety of parameters. What is the best way for this endpoint to talk to this endpoint may decide what kind of connection. This end point is going to establish with this end point. That is all part of connection management that is happening in the transport layer of the Java run time. And the connection manager is also responsible for locating the dispatcher for a remote method that is being invoked on this end point. So. A transport is listening on a channel. And when an invocation comes in, then this transport is responsible for identifying, or locating, the dispatcher on this domain, which will know how to carry out that invocation. And the connection managers also responsible for managing the liveness of the connection. Because, if any point goes away, it needs to know that and inform this domain that, oh this particular end point is gone. So, take the appropriate action. So that kind of liveness monitoring is part of connection management. So the last abstraction I mentioned is the notion of connection itself. So once a channel has been established. Then the transport can do IO on this channel using connections. So, the path for the transport layer is in connection management. It listens for an incoming request. When an incoming request comes in. It then establishes a channel, and the channel that is established for communication, which is a mutual agreement between these two endpoints. It choses a transport that is most appropriate for that and once the channel has been established, a connection. Is now made between this endpoint and this endpoint through this channel. And now these two endpoints can do I/O on the channel using the connection. So that's how the transport mechanism of RMI works. As we saw, the transport mechanism sits below the RRL layer. And so it allows all the object invocations to happen through the transport layer. And the RRL layer is the one that is deciding, what are the right transport to use depending on the location of the two endpoints, where the client is and where the server is. Depending on that, it might decide what would be the right transport to use. Whether it should use TCP or UDP and so on. And gives that command to the connection manager which is part of the transport layer of the software stack. So that the established channel can be established and then a connection can be used for actual transport. Of the implementation between the client and server. So in summary, the distributed object model of Java is a powerful vehicle for constructing network services and what we say in this lesson. Is a glimpse of the classes that are available in the distributed object model that makes the life of the developer easy in terms of creating network objects and making it visible for clients to use anywhere. And the power of the RRL layer in dynamically deciding how to make the client-server relationship. Similar to the sub contract mechanism that we saw in spring and we also saw the flexibility in the connection management. Allowing different kinds of transport exist between the client and the server depending on the location of the client and network conditions and so on.
</li> 
</ul>

<h2>13. Java RMI Conclusion</h2>
<ul>
  <li>There are some more subtle issues involved in the implementation of the RMI system, including distributed garbage collection, dynamic loading of stubs on the client side, sophisticated sandboxing mechanisms on the client and the server sides to ward off security threats and so on. I encourage you to learn about these issues by reading the assigned paper and also surfing the Net. The main point I want to leave you with is that many ideas that start out as pie in the sky research becomes usable technology when the time is ripe.
</li> 
</ul>

# L06c: Enterprise Java Beans
<h2>1. Enterprise Java Beans Introduction</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/30.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>Welcome back! Let's connect the dots. We started with the technical issues in the structure of an operating system for a single CPU, then a parallel machine, then a distributed system. We saw how object technology with it's innate concepts of inheritance and reuse helps in structuring operating systems at different levels. Now, we go one step further. How do we structure the system software for a large scale distributed system service? It's too limiting to call it an operating system. Large scale distributed service.</li> 
  <li>As we continue this lesson, we'll get a glimpse of how object technology has gone ballistic to provide the services that you're reliant on for your everyday internet e-commerce experience.</li> 
  <li>In this lesson, we will describe enterprise java beans and the term java bean is used to signify reusable software components. That is many objects, java objects, in a bundle so that it can be passed around easily from one application to another application for reuse.
</li> 
</ul>

<h2>2. Inter Enterprise View</h2>

<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/31.JPG?raw=true" alt="drawing" width="500"/>
</p>

<ul>
  <li>I'm sure all of us use, routinely, services on the internet such as email through Google or Yahoo. And perhaps purchase things using eBay or make orders for airline reservations and so on. And when we do that, we think of an enterprise that we are accessing from our work station or laptop or personal mobile device. We think of an enterprise as a monolithic entity.</li> 
</ul>
     
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/32.JPG?raw=true" alt="drawing" width="500"/>
</p>          
<ul>
  <li>But, in fact, if you look inside the enterprise, the enterprise, the intra enterprise view, is pretty complicated. There's a whole bunch of services and servers that are interconnected, there may be marketing division, the sales division, the production division, inventory division, the research division and so on. All of these constitute what an enterprise is. So internally the view of the enterprise is much more complex than what you see from the outside coming in and using services provided by a particular enterprise.</li> 
</ul>

<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/33.JPG?raw=true" alt="drawing" width="500"/>
</p>    

<ul><li>Things get a lot more complicated in this day and age because when we access an enterprise, in fact, the enterprises, they talk to one another. And this is, what is usually called a supply chain model, and so on. Where, the service that you are, requesting may not be serviced by, a single entity but may actually involve the entity that you're contacting, contacting other entities in order to. Put together a solution for a particular request, and what is even more challenging is when enterprises merge. For instance, if three companies merge together, and this happened a while back. There's a company called Digital Equipment Corporation that got bought out by Compaq and those two merged, and later on HP bought out Compaq. And so you can see, that when things like this happen, the inter-enterprise view is much more complex. And now when companies merge like this, the idea of an enterprise, the idea of an enterprise, becomes an amalgam of three different entities coming together, in this example for instance. So the enterprise transformation challenges are many: interoperability of the systems that constitute different enterprises, interface compatibility when such merging happens, system evolution. You know, things are not stagnant, now this transformed enterprise has to continuously evolve as well. Scalability, reliability and the cost of maintaining a complex system like that. All of these things are the challenges that have to be faced both internally and across enterprises.</li> 
</ul>

<h2>3. Enterprise Java Beans Example</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/34.JPG?raw=true" alt="drawing" width="500"/>
</p>   
<ul>
  <li>We often refer to services that we're using on an everyday basis, such as airline reservation or Gmail or websurfing, as giant scale services, as opposed to the services that you get within your organization. Example, a file server. There's a later module in this course called Internet Scale Computing, and in that we will discuss programming models and resource management issues for providing such giant scale services. The focus of this point however, is to show how object technology facilitates structuring such services.</li> 
  <li>Let's look at an example to put things in perspective. Let's say you want to purchase a round trip ticket to go from Atlanta to Chennai, India. With a few clicks, you can send your request over to a portal such as Expedia. And Expedia then goes to work for you. It contacts a whole bunch of different airlines, gets the best options that are available from all these different choices, and then it comes back to you with a bunch of options. Now you may take your own sweet time deciding which one of those you may want to pick, based on cost, perhaps convenience, guarantees. For example, you don't want your baggage to end up in Timbuktu. So, based on all of that, you may want to make a decision. Maybe you have to talk to your spouse or significant other, siblings, children, so on, in order to make the final decision. Finally you decide, then commit to buying the ticket, and then Expedia will complete the transaction based on the choice that you made. And you get your ticket and life is good. Well, not so fast. While you are busy procrastinating with your choices, there's another person who is planning almost an exact similar trip to yours. Same dates, same constraints, same destination, and so on. And you can immediately see that, without your realizing, you are actually competing for resources. In this case, a physical resource, a seat on a particular flight going from Atlanta to Chennai, India, with others that you don't even know exist on this planet. Therefore, the service provider, in this case multiple enterprises involved, Expedia and all the airlines together, that are handling your request, they all have to work together to make sure that the result, any resource conflict that might occur between simultaneous requests across space and time coming from several different clients.</li> 
  <li>So all the issues that we've discussed in the context parallel and distributed systems, synchronization, communication, and immediacy of actions, concurrency, all of these become important. And they surface in this very simple example across space and time. And additionally, all services need some common features. For example, a shopping cart on your browser. And in fact, even though this particular example is illustrating an airline reservation, if it comes to booking a ticket on a train, or getting hotel reservation, or booking tickets to go see a game, all of those things have similar requirements. And many of them are probably repeatable. And many of them, such as the shopping cart in this example, are features that might be needed even if the services that you're talking about are completely different, such as an airline reservation and hotel booking. So since the same issues crop up in the implementation of each new service, we don't want to reinvent the wheel every time. This is where object technology comes in, the power of reuse of components.
</li> 
</ul>

<h2>4. N Tier Applications</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/35.JPG?raw=true" alt="drawing" width="500"/>
</p>   
<ul>
  <li>Now such applications are what are called N-tier applications because if you look at the software stack that comprises an application such as this, you'll see several different layers. You have a presentation layer. And the presentation layer is the one that is responsible for painting the screen on your browser. Perhaps dynamically generating the page based on the request you made. And there may be application logic that corresponds to what the service is providing. And there is business logic that corresponds to the way airfares are decided, seats are allocated, all these kinds of things. And there's a database layer that accesses the database that contains information about all the things that the application and the business logic have to decide on in order to satisfy a particular request. And all these different layers have to worry about many of the issues that we're already familiar with, in the context of writing, parallel programs and distributive programs, and those include persistence for actions.</li> 
  <li>For example, let's say I made a choice, but I haven't completed the booking. I may go away and come back later on, in order to complete that booking. So persistence is something that I might need. You need a notion of transaction because I have initiated a particular operation and I have not completed it and so transaction properties may be needed in order to make sure that a reservation that started Is finally complete and I have made the booking. Caching of data that you pulled in from a database server so that you can access the database more quickly. Clustering, which corresponds to taking a set of related services and clustering it together in order to improve the performance of the service. And similarly clustering the data that you're accessing from a data base server. All of these are issues, and of course one of the things that we worry about a lot this days in Ecommerce is security, in particular when we are communicating financial information, credit card information, and personal information like social security Id's and so on We worry a lot about services provided by the server and that my personal information is not compromised in any fashion. So these are all the sets of issues that N-tier Applications have to worry about in making sure that the services it provides are trustworthy from an end user's point of view. </li> 
  <li>How do we structure an N-tier application like this? The things that we want to reduce is reduce the amount of network communication because that results in latency, reduce security risks for the users which means that the business logic should not be compromised. And increase the concurrency for handling an individual request. For instance, there's an individual request, but in processing this request, there's an opportunity to exploit parallelism. Often times, these are called embarrassingly parallel applications because even though this request seems like a single request, there's an opportunity to exploit parallelism. And the kind of parallelism is embarrassingly parallel because the same query. I want to find out the availability of seats on a particular date. I don't care about which airline I go by. That's an opportunity for parallelism for the expedia server, to go in parrallel to multiple airlines and find out the availability of seats on the dates that I requested. Similarly, there's opportunity for exploiting concurrency across several simultaneous requests that are coming in. And also for clustering the computation that may have to be done on the server for computations that are common across simultaneously arriving requests. We want to reuse components aggressively. By components we mean portions of the application logic that can be reused in constructing these applications as well as in the execution of the components in order to service the requests that are coming in simultaneously from several different clients.
</li> 
</ul>


<h2>5. Structuring N Tier Applications</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/36.JPG?raw=true" alt="drawing" width="500"/>
</p>   

<ul>
  <li>To structure the N-tier applications we're going to talk about one particular framework as an example. It's just as an example, there are other frameworks that provide similar functionality to the JEE framework which is called the Java Enterprise Edition framework. And in the JEE framework there are four containers for constructing an application service. And containers you can think of as protection domains implemented typically in a Java virtual machine.</li> 
  <li>In the JEE version of, of building N-tier applications there are four containers there are the client contain and there is an applet container for the client, which will reside typically on a web server. And this is the one that interacts with the browser on the end client. And the presentation logic that I mentioned to you earlier is provided in a container, which is called a web container, and this is the guy that is responsible for dynamically perhaps creating the pages that have to be sent by the web server back to the browser of the client. And there is an EJB container, which is the one that manages the business logic that corresponds to what needs to be done in order to carry out the request that is come in from the end client. And there may be a database server, that the business logic is communicating with in order to get access to the data that it needs to process the request that came in. So these are the four containers: the client container, the applet container, the web container and the EJB container that are, the containers that are available for packaging the objects that constitute. The entire application for providing a particular service, for example, airline reservation service or a hotel reservation service.</li> 
  <li>The key hope is that we want to exploit as much as possible, reuse components, and for this purpose continuing sort of the coffee analogy starting with Java. The word bean is used to indicate a unit of reels, that is, a bundle of Java objects providing a specific functionality. For example, there may be a bean that provides the shopping cart function. So that becomes a unit that reuse in constructing an N-tier application. The containers that I talked about here host the beans. That is, a container allows you to package a whole bunch of Java beans and make it available in this container, in the JEE framework.</li> 
  <li>There are four types of beans, one type of bean is called an entity bean. For instance an entity bean maybe a row of a database. If you think about the database holding employee records for instance, one drawer of the database may correspond to all the employees whose last names start with the alphabet "a". And typically entity beans are persistent objects with primary keys. And the persistence for the entity bean may be built into the bean itself and that is what is called bean management persistence, or it may be built into the container into which that entity bean is instantiated. In either case since we are dealing with objects that may need persistence, it is important that the persistance for that object is handled somewhere either in the entity itself or the container into which that entity is being hosted.</li> 
  <li>The second type bean is what is called a session bean. And the session bean typically is associated with a particular client. And a particular session, meaning a temporal window over which a client is interacting with the service. That is what a session bean may be holding. And a session bean could be a stateful session bean, meaning, for instance, I am ordering, let's say, a computer by contacting a portal for Dell. In that case, the session that I'm establishing with the Dell portal, that session has to be stateful, because it has to remember what choices I'm making. I may actually keep those choices alive, go away for a while, come back the next day, and continue with my purchase. So, sessions could be stateful. There could also be stateless sessions. For instance if I start an email session using my browser with Google using Gmail, that session maybe stateless. I go away, everything that I did during that session can be thrown away because I'm going to start a brand new session when I reinitiate a connection with a Gmail server. So in that sense, a session bean could be a state-full session bean or a stateless session bean.</li> 
  <li>And the third type of bean is what is called a message-driven bean. This kind of bean is useful for asynchronous behavior. For instance, I might be interested in getting the stock quotes, I might have a stock quote ticker on my browser and I might want to get updates on the movement of stocks of a particular company that I'm interested in. And that would be something that is accomplished using a message bean, which is having this asyncrhonous behavior. Stock ticker is an example, news feed is an example, RSS feeds that you typically are using, these days, are examples of message driven beans. And the finer we make these beans, each of these beans is denoting a functionality, but if you can have fine grained Versions of these beans. That gives a greater opportunity to enhance a concurrency for dealing with an individual request that's coming into your application's server, or there could be concurrent requests. In addition to my own request, there could be parallel requests coming in. All of those can be dealt with more concurrently if we implement these beans at a finer level of granularity. But if you implement the bean at a finer level of granularity that means that the business logic is also getting more complex. So, there is always this trade off in structuring end clear applications that we made have a complex business logic In order to support finer grain concurrency or I might choose to keep the business logic very simple and use coarse-grained beans. And this is where the core of what we are going to discuss lies, and that is. We are going to discuss different design alternatives for structuring such entity application servers.
</li> 
</ul>

<h2>6. Design Alternative (Coarsegrain Session Beans)</h2>

<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/37.JPG?raw=true" alt="drawing" width="500"/>
</p>   

<ul>
  <li>So the first design alternative that we're going to look at is using coarse-grain session beans. In this structure that I'm showing you, we're only looking at the web container. The EJB container because the applet container that interfaces with the client is in the web browser. So we don't worry about that. We'll talk only about how we structure the web container and the EJB container in the different design alternatives. So the web container contains the presentation logic and in the structure that I'm showing you a servelet corresponds to an individual session with a particular client. So, this box represents a particular client. This box represents a second client. And there's a presentation logic commensurate with servelet one, that is client number one. And similarly, presentation logic commensurate with servelet two, which is client number two. And there's a coarse grain session bean that is associated with each of these servelet. And in turn the session bean corresponds to the client that is being served through the servelet number one. And similarly, servelet number two is served by this session bean. And as the name suggests, the session bean is responsible for the specific needs of the particular client that it is serving for this particular session.</li> 
  <li>Therefore, the session bean will worry about the data accesses that are needed to the database in order for the Business Logic to do its thing. So if, let's say, we're doing an airline reservation system and if this is requesting a particular booking, then the session bean is going to be the one that contacts the database server in order to pull the specific dates and airline reservation. Information that is needed for the business logic to do the pruning and selection commensurate with whatever this particular client is requesting. And there are multiple sessions that are contained in this EJB container, depending on the number of clients that have simultaneously temporally made requests to this particular service. So the EJB container has to provide some service for all the sessions that are concurrently going on in this server. All of the data accesses that are needed for a particular session is taken care of by the session bean. And therefore, the amount of help that we need from the EJB container, in terms of services, is pretty minimal for supporting this particular model, and in fact, it is confined to any conflicts that might arise in terms of external accesses for satisfying the request of these different session beans. So the EJB container service that would be needed is primarily for coordinating, if any across concurrent independent sessions. An example would be, if they want to access the same portion of the database for writing some records.</li> 
  <li>In that case, they may need some coordination help from the EJB container service. The other important attribute of this structure is that the business logic is confined to the corporate network. It is not exposed to the outside world because it's not contained in the web container, it is contained in the EJB container and therefore the business logic is not exposed beyond the corporate network. That's a good thing. So, the pros of this particular structure is that you need minimal container services and also that the business logic is not exposed to the outside world.</li> 
  <li>But the cons for this particular structure is, this application structure is very akin to a monolithic kernel that we've talked about a lot. There is very limited concurrency for accessing different parts of the database. For instance, I mentioned that the services provided by these giant scale services tend to be embarrassingly parallel. So there is a lots of opportunities for pulling in data, example would be let's say, that the particular query is to compile demographic distribution of all the employees in the company. In that case, there's an opportunity to pull in lots of data simultaneously from the database. But unfortunately, the structure doesn't allow you to exploit such concurrency. So in other words, this core screen session been structure represents a lost opportunity. For accessing and pulling lots of data from the database in parallel for satisfying either the same request or even concurrent requests that may be accessing the same portions of the same database.
</li> 
</ul>

<h2>7. Design Alternative (Data Access Object)</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/38.JPG?raw=true" alt="drawing" width="500"/>
</p> 
<ul>
  <li>The second design alternative I'm going to talk about mitigates exactly the problem that I had mentioned earlier. And that is, you want parallelism for accessing the database because, this is probably one of the slowest link in the whole processing of request because pulling in data from the database is going to take a lot of time. Both in terms of I/O that has to be done through disks as well as the network communication to pull in the data into the container where the processing needs to happen. And for that purpose the structure that we have here is to push the business logic as part of this container in which the servelet and the presentation logic was there we add the business logic also and make it a three tier software structure here. Servelet presentation logic and business logic, and all of the data access is going to be done through what are called entity beans. As I mentioned earlier, entity beans have persistence characteristics, and in this particular example i can think of the entity bean as representing one row of the database. So the data access object are implemented using a whole bunch of entity beans and you can decide as the designer whether an entity bean is responsible for one row of the database or maybe for a set of rows of the database. But in any event what we've done is, we've taken the parallelism that is available in terms of data access to the database and encoded it through the entity bean so that they can be parallel access to the unit of granularity that we have in terms data base access. So the EJB container now contains these entity beans. So now if a servelet that is serving a particular client needs to access some portion of the database, it can form more parallel requests to these entity beans, to as many entity beans as it wants. And all of those entity beans can work in parallel on behalf of a single client. And pull in the data that is needed and serve it up to the business logic so that the business logic can then do its thing. So we are reducing the time for data access by having this parallel structure and exploiting the available concurrency that may be there in terms of I/O performance, and also even if there are parallel requests, those parallel requests may want access to the same portion of the database. If you think about the example I gave you of two difference individuals wanting to make airline reservation for exactly the same dates and the same set of constraints. Then there may be an opportunity for this entity bean to cluster the request coming from several different end clients and amortize the access to the database server across several different clients that are temporally happening at the same time.</li> 
  <li>I mentioned entity beams usually are dealing with persistent state, which means that the persistence has to be provided at some level to these entity beans. So that persistence has to be provided to the data accessed object at some level, which are using these entity beans. It could be done at the level of individual entity beans, which is called the bean managed persistence. If the bean is managing the persistence needs of the data access object, then that is called bean managed persistence. Or it could be that the container is providing that facility, in which case the persistence needs of the data access object is provided by the container and that is called container managed persistence. So these are two different design choices we can make in this structure. The structure is the same for the design alternate of two. That is, we're using entity beings to implement data access objects, and we're deciding the granularity of the data access object based on the level of concurrency that you want in constructing this application service. But within that choice there are two possibilities again in terms of how we provide persistence for the data access object, either by providing it in the entity bean itself, or using the container service to provide that.</li> 
  <li>So this, once again, points to opportunities for reuse of facilities that may be available. The same container-managed persistence may be usable for different types of applications. One application may be an airline application, another application may be a portal for hotel booking. All of those different applications may be able to reuse container-managed persistence that's available in the structure.</li> 
  <li>So the pros of this structure is first of all, the concurrency that you can actually exploit concurrency for data access for the same client in parallel or even across different clients by amortizing the data access. That may be needed concurrently for similar services that are overlapping in terms of data usage. That's the good news.</li> 
  <li>There's one con to this approach, and that is, because we moved the business logic into the web container from the EJB container, it exposes the business logic to the outside network. We are not confined to the corporate network but the business logic is exposed outside the corporate network in this design alternative. So, all the data access code that you used to be in the session bean in the previous structure that I talked about. All the data access code is now moved into this entity bean. That's how we get the parallelism in the fact that there are multiple entity beans that are carrying the same data access code and they could be accessing different portions of the database concurrently resulting in exploitation of parallelism and reusing the latency for the business logic to get all the data it needs from the data base in order to do its work.
</li> 
</ul>


<h2>8. Design Alternative (Session Bean With Entity Bean)</h2>
<p align="center">
   <img src="https://github.com/audrey617/CS6210-Advanced-Operating-Systems-Notes/blob/main/img/l6/39.JPG?raw=true" alt="drawing" width="500"/>
</p> 

<ul>
  <li>The second design alternative gave concurrency but at the cost of exposing the business logic, and the third design alternative that I'm going to explain to you, is going to correct that, it's using session bean with entity bean. The idea is that, we're going to associate it with each client session, a session facade, it's a design pattern that allows you to construct a session and associate it with a particular client. So, for instance, in this case, this session facade corresponds to servelet 1, which corresponds to the client that it is serving similarly this session facade, serving client number 2. And as in the first design, what you see is that the web container contains only the servelet and the presentation logic that is associated with that particular servlet. Now the business logic, is moved back into the EJB container, and it sits with the session facade. And we still have the data access objects implemented using the entity  bean concept that I mentioned in the second design alternative. So, the session facade is worrying about all the data access needs of its associated business logic. Similarly, this session facade is worrying about all the data access needs of this business logic, and what the session facade is going to do is, it's going to form out the data access requests corresponding to the business logic associated with this session. So, there's an opportunity again, to exploit parallelism because you can form out parallel requests to multiple entity beans. That are handling the data access to different portions of the database and similar to the second, design alternative, we're going to structure this database to be at whatever level of granularity that we think is the right one. So this entity bean may be responsible for an individual role or a cluster of rows and so on. And that way, we can have the granularity that we want for parallel access so that the business logic can be served in parallel, and at the same time, we have moved the business logic back into the EJB container. So, the business logic is not exposed outside the corporate network.</li> 
  <li>We have a couple of choices of how we want to structure the session bean with the enity bean. Now the web container is going to use RMI, a remote interface in the distributed object framework of Java, in order to communicate with the business logic, and the session facade is going to communicate with the entity bean either using RMI. In that case, the interaction between the session facade and the entity bean is very similar to the interaction between the servlet and the session facade. That is, it'll use RMI. Or, we can choose to construct the interface between the session facade and the entity bean, using local interfaces. And the reason why we may want to choose one or the other, using the RMI allows us to, sort of, keep this entity bean wherever we want in the network. On the other hand, if we chose the local option, what we're seeing is that we will co-locate the entity beans in the same EJB container as the business logic and the session facade. The advantage of doing that is that because it is local, we don't have to incur network communication, in order to go and fetch the data from the entity bean. The entity bean, of course, has to fetch it from the database servers, but once it fetches it from the database servers, it doesn't have to go through the network in order to give it to the business logic if you're using local interfaces. So that's another bifurcation within this design alternative. We can choose to construct this portion of the application using remote interface or local interface.</li> 
  <li>And the prose of this structure is in some sense getting the best of both worlds. We're not exposing the business logic, which was the virtue of the first design alternative, and we're also getting concurrency through the data access object encoded as entity beans. So you get the concurrency and the fact that the business logic is within the corporate network. Both of those good features are available in this design alternative.</li> 
  <li>Is there a con? We are incurring additional network access in order to do the servers that we want for the data access, and that can be mitigated by call locating, the entity bean, and the session facade in the same EJB container. So that's a choice that you can make.</li> 
  <li>So these are the 3 design alternatives that we talked about. One is a coarse-grain session bean alternative. The second is a finer-grained data access object alternative, and the third is sort of putting together the first two. Putting the session bean as a facade. To actually access the data access objects, which are encoded in entity bean so that you can get concurrency. Notice that in talking about these different design alternatives, we're only talking about how to break up that application, the logic of that application, which consists of presentation to the client, business logic that has to do with decisions that this enterprise has to make in order to service this request, and database access in order to get the data that is needed in order to do the work that is involved. In serving up the needs of a particular client. Lots of things that are needed in addition to writing about the application logic itself. And those are things like security, persistence, and so on. The power of object technology is the fact that So that's the thing that I wanted to start with and I wanted to give you the different design alternatives that exist in structuring these complex services using the object technology to reuse components instructed in structuring complex applications.</li> 
</ul>


<h2>9. Enterprise Java Beans Conclusion</h2>
<ul>
  <li>So this lesson showed the power of the object technology for structuring complex application servers. EJB, allowed developers to write business logic, without having to worry about crosscutting, concerns such as security, logging, persistence and so on. As a homework, what I would want you to do, is understand the design choices that we discussed in the lesson and analyze qualitatively the performance implications of those design choices, with respect to concurrency, pooling of resources, number of object classes, lines of code and so on. And read the paper that I've assigned to you, as part of the reading material for this course, in this topic, and relate the arguments they present in the paper against your own qualitative analysis. A word of caution though, EJB has evolved, considerably, from the time of this paper. But the principals that are discussed in this paper apply to the way complex entier applications are structured to this day.
</li> 
</ul>

<!-- <h2></h2>

<p align="center">
   <img src="" alt="drawing" width="500"/>
</p>

<ul>
  <li></li> 
  <li></li> 
  <li></li> 

</ul> -->
